# gastronomy/perception

<p class="has-line-data" data-line-start="0" data-line-end="1">3DBlender repository:</p>
<p class="has-line-data" data-line-start="2" data-line-end="3">The first step is the generation of the data which will be used to further train the model. Follow these steps to generate the data.</p>
<p class="has-line-data" data-line-start="4" data-line-end="5">CLEVR Dataset Generation:</p>
<ol>
<li class="has-line-data" data-line-start="5" data-line-end="6">Download blender 2.79b</li>
<li class="has-line-data" data-line-start="6" data-line-end="7">Follow Step 1 of this wiki : <a href="https://github.com/facebookresearch/clevr-dataset-gen">https://github.com/facebookresearch/clevr-dataset-gen</a></li>
<li class="has-line-data" data-line-start="7" data-line-end="8">Download some obj mesh files and place them in 3dblender/data/shapes directory. There are some vegetable meshes already there.</li>
<li class="has-line-data" data-line-start="8" data-line-end="9">The script provides multiple argumetents for configuring data generation. These arguments can be seen in render_images.py file.</li>
<li class="has-line-data" data-line-start="9" data-line-end="13">Sample data generation command:<br>
blender --background --python render_images.py – --num_images 1000  --use_gpu 1 --height 256 --width 256 --dataset_name CLEVR_TEST --do_random_rotation 1  --min_objects 1 --max_objects 3<br>
This command will generate multiview scenes with 1-3 objects in each scene. Each object will be subjected to random rotation.</li>
</ol>
<p class="has-line-data" data-line-start="13" data-line-end="15">Follow the steps below to start the training.<br>
pytorch_disco_clone repository:</p>
<ol>
<li class="has-line-data" data-line-start="15" data-line-end="31">
<p class="has-line-data" data-line-start="15" data-line-end="16">Create conda environment using pydisco_environment.yml.</p>
<p class="has-line-data" data-line-start="17" data-line-end="24">Install torch<br>
<code>conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</code><br>
Install cmake<br>
<code>conda install -c anaconda cmake</code><br>
Install cv2 (opencv):<br>
<code>conda install -c conda-forge opencv</code><br>
Install cuda corr3d</p>
<pre><code class="has-line-data" data-line-start="25" data-line-end="29">cd cuda_ops/corr3d
python setup.py install
cd ..
</code></pre>
<p class="has-line-data" data-line-start="29" data-line-end="30">Install tensorboardX from <code>https://github.com/zuoym15/tensorboardX</code></p>
</li>
<li class="has-line-data" data-line-start="31" data-line-end="32">
<p class="has-line-data" data-line-start="31" data-line-end="32">Execute ‘cd pytorch_disco_clone’</p>
</li>
<li class="has-line-data" data-line-start="32" data-line-end="33">
<p class="has-line-data" data-line-start="32" data-line-end="33">Clevr data needs to be converted into appropriate format for this repo. Update the folderMod_dict dictionary in setup/write_npy_clevr_veggies.py with the folder name that was generated by 3dblender. Use a unique key (which we will call mod). Finally execute the data preparation  script: python setup/write_npy_clevr_veggies.py &lt;mod_name&gt;</p>
</li>
<li class="has-line-data" data-line-start="33" data-line-end="40">
<p class="has-line-data" data-line-start="33" data-line-end="40">exp_clevr_sta.py and exp_nel_sta.py: These files hosts all the experiment configurations for training on clevr dataset. Each experiment is a group of configuration (like learning rate) and the dataset name. You can add a new experiment like this:<br>
exps[&lt;exp_name&gt;] = [<br>
&lt;param1&gt;,<br>
…<br>
…<br>
&lt;paramN&gt;<br>
]</p>
</li>
<li class="has-line-data" data-line-start="40" data-line-end="41">
<p class="has-line-data" data-line-start="40" data-line-end="41">Any checkpoint model that you want to be loaded should be placed at the end in pretrained_nets_carla.py file</p>
</li>
<li class="has-line-data" data-line-start="41" data-line-end="45">
<p class="has-line-data" data-line-start="41" data-line-end="45">Hard positive mining training: Run this command:<br>
python <a href="http://main.py">main.py</a> nel --en clevr_multiple_trainer_hard_exp5_pret_moc_orient --rn &lt;run_name&gt;<br>
This will execute expectation maximization loop to learn better features.<br>
Add the checkpoint name at the end of pretrained_nets_carla.py for next stage of training.</p>
</li>
<li class="has-line-data" data-line-start="45" data-line-end="53">
<p class="has-line-data" data-line-start="45" data-line-end="48">Clustering training: Run this command:<br>
python <a href="http://main.py">main.py</a> cs --en clevr_trainer_gen_examples_multiple --rn &lt;run_name&gt; to<br>
initialize the clusters</p>
<p class="has-line-data" data-line-start="49" data-line-end="50">Then run this for cluster training:</p>
<p class="has-line-data" data-line-start="51" data-line-end="53">python <a href="http://main.py">main.py</a> cs --en clevr_trainer_quantize_object_no_detach_rotate_50_init_examples_hard_only_embed_frozen --rn &lt;run_name&gt;<br>
Add the checkpoint name at the end of pretrained_nets_carla.py for next stage of training.</p>
</li>
<li class="has-line-data" data-line-start="53" data-line-end="56">
<p class="has-line-data" data-line-start="53" data-line-end="55">Self improving detector training: Run this command:<br>
python <a href="http://main.py">main.py</a> cs --en det_trainer_big_freeze_vq_rotate_selfimproveIterate_deep_multiple_maskout_hardneg --rn &lt;run_name&gt;</p>
</li>
</ol>