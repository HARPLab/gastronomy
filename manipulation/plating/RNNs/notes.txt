Thoughts:
- For attention model, train a many to one sequence mapper. Input a sequence
    of images and predict the location of the next object
- need to train the model to make a prediction at each point in the sequence
- for the structure maybe:
    - give a sequence of images
    - use the images from yolo to train?
        - so use the bounding boxes from YOLO to train the model to predict
            a mask that shows the position of the next object.
        - set the bounding box of the predicted object to
            be the label as a feature vector
        - but you'll need to change all of the bouning boxes to be
            the same size as the image. so the pixels wihtin the 
            bounding box are ones and everything else is a zero.
            then vectorize it and use that to compute the error with
            the predicted mask from the model
        - might want to convert the bounding boxes into gaussian distributions
            - so something like the heat map or use a sigmoid or something

    - need the model to predict a gaussian attention mask maybe?
- Teacher forcing might help (ie, giving the previous input as an input
  for the current time-step during training)

Questions:
- What should be the input to the model?
    - could give a sequence of images to train
    - maybe give the output of yolo (ie, the object detections/predictions)?
    - Should i learn an embedding for the images? aplication doesn't have 
      that much memory honestly might be able to just use a vanilla RNN

Suggested architechture:
    1) Have an input sequence of images, apply a convolution to them 
        to create embeddings for them
    2) Use these as the time sequence inputs to the LSTM
    3) Use attention mechanism in between the embedding stage and 
        LSTM stage to get masks (will need some type of context vector, maybe as input to attention)
    4) Pass through the LSTM (might want to use a convolutional LSTM at some point)
    5) have some type of convolutional decoder to make the output of the LSTM
        the same size as the input images
    6) compute the loss using the bounding boxes predicted from YOLO as the labels
